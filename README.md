# ğŸ› ï¸ Intuit Build Challenge: Combined Solutions

This document combines the technical READMEs for the two required assignments in the Intuit Build Challenge, demonstrating proficiency in **Concurrent Programming (Assignment 1)** and **Functional Programming/Data Analysis (Assignment 2)**.

---

## ğŸ’» Assignment 1: Producer-Consumer Simulation (Java 17)

This project is a robust, thread-safe implementation of the classic Producer-Consumer pattern. It is built in Java 17 and demonstrates core concurrent programming competencies, including thread synchronization and the wait/notify mechanism, built from scratch without high-level concurrent collections.

### ğŸ¯ What Is Achieved

This solution satisfies all specific testing objectives outlined for Assignment 1:

- **Thread Synchronization**: Guaranteed data integrity with zero race conditions. This is implemented using Java's intrinsic locks (`synchronized` blocks) in `SimpleBlockingQueue`.
- **Concurrent Programming**: Achieved true parallel execution of data production and consumption. This utilized the `Runnable` interface to decouple tasks and the `Thread` class to spawn separate execution stacks.
- **Blocking Queues**: Implemented a finite buffer that automatically halts threads when limits are reached. The Producer blocks (`wait()`) when the queue is full, and the Consumer blocks (`wait()`) when the queue is empty.
- **Wait/Notify Mechanism**: Used `Object.wait()` to release the lock and suspend threads when the queue state is invalid (Full/Empty), and `Object.notifyAll()` to wake up waiting threads after a state change (Item added/removed).
- **Robustness**: Implemented the Poison Pill Pattern (Sentinel Value -1) for graceful consumer shutdown and strict input validation for queue capacity.

### ğŸ“‚ Project Structure (Assignment 1)

```plaintext
producer_consumer_assignment/
â”œâ”€â”€ pom.xml
â”œâ”€â”€ src/
â”‚   â””â”€â”€ com/assessment/
â”‚       â”œâ”€â”€ app/
â”‚       â”‚   â””â”€â”€ Main.java                 # Entry point and simulation driver
â”‚       â”œâ”€â”€ core/
â”‚       â”‚   â””â”€â”€ SimpleBlockingQueue.java  # Custom thread-safe queue (The Monitor Object)
â”‚       â””â”€â”€ workers/
â”‚           â”œâ”€â”€ Producer.java             # Runnable task
â”‚           â””â”€â”€ Consumer.java             # Runnable task
â””â”€â”€ tests/
    â””â”€â”€ com/assessment/tests/
        â””â”€â”€ TestBlockingQueue.java      # Comprehensive test suite
```

### ğŸš€ How to Run (Assignment 1)

**Prerequisites**: Java Development Kit (JDK) 17 or higher, Maven 3.x.

#### Run the Application (Recommended):

```bash
mvn exec:java -Dexec.mainClass="com.assessment.app.Main"
```

#### Run Unit Tests & Coverage:

```bash
mvn clean test
```

**Coverage Status**: ~93% (Verified by JaCoCo).

---

## ğŸ“Š Assignment 2: Amazon Product Stream Analysis (Python 3)

This project solves the data analysis challenge using Python 3 and demonstrates proficiency with Functional Programming paradigms by implementing a custom, memory-efficient Stream API powered by Python Generators. The goal is to analyze raw, unstructured sales data ("dirty data") without relying on heavy external libraries like Pandas.

### ğŸ¯ What Is Achieved

This solution satisfies all specific testing objectives outlined for Assignment 2:

- **Functional Programming & Stream Operations**: Logic is expressed as declarative stream chains (`.map().filter().reduce()`), using pure functions for all cleaning logic. All data is modeled using immutable `@dataclass` structures.
- **Lazy Evaluation (Memory Efficiency)**: The custom `Stream` class (`core/stream.py`) uses Python's `yield` keyword (Generators). Data is processed one item at a time, resulting in O(1) memory complexity, as the dataset is never fully loaded into memory.
- **Data Aggregation**: Performs various aggregation and grouping operations on sales data. This includes computing Total Revenue, Category Averages, and Top Discounts.
- **Lambda Expressions**: Anonymous functions are used extensively for passing behavior into the stream engine (e.g., as predicates for filtering or functions for mapping).
- **ETL Pipeline**: Includes robust real-time cleaning logic to sanitize "dirty" data (currency symbols, percentage signs) from the `amazon.csv` dataset.

### ğŸ“‚ Project Structure (Assignment 2)

```plaintext
.
â”œâ”€â”€ run.py                          # Entry point (Bootstraps the application)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ amazon.csv                  # Input dataset
â”œâ”€â”€ src/
â”‚   â””â”€â”€ sales_analysis/
â”‚       â”œâ”€â”€ app.py                  # Business Logic (The Analytical Queries)
â”‚       â”œâ”€â”€ core/                   # Domain Layer
â”‚       â”‚   â”œâ”€â”€ models.py           # Immutable Data Structures (@dataclass)
â”‚       â”‚   â””â”€â”€ stream.py           # The Custom Stream Engine
â”‚       â””â”€â”€ ingestion/              # Data Layer (ETL)
â”‚           â”œâ”€â”€ cleaning.py         # Parsing Utilities (Pure Functions)
â”‚           â””â”€â”€ loader.py           # CSV Generator
â””â”€â”€ tests/
    â”œâ”€â”€ test_app.py                 # Integration tests
    â””â”€â”€ ...                         # Unit tests
```

### ğŸš€ How to Run (Assignment 2)

**Prerequisites**: Python 3.8 or higher (Standard Library only).

#### Run the Analysis Report:

```bash
python3 run.py
```

#### Run the Test Suite:

```bash
python3 -m unittest discover -s tests -v
```

#### Check Code Coverage:

```bash
python3 -m coverage run --source=src -m unittest discover -s tests -v
python3 -m coverage report -m
```

**Coverage Status**: 100%.